{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2249698 entries, 0 to 2249697\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   PRODUCT_ID       int64  \n",
      " 1   TITLE            object \n",
      " 2   BULLET_POINTS    object \n",
      " 3   DESCRIPTION      object \n",
      " 4   PRODUCT_TYPE_ID  int64  \n",
      " 5   PRODUCT_LENGTH   float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 103.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCT_ID               0\n",
       "TITLE                   13\n",
       "BULLET_POINTS       837366\n",
       "DESCRIPTION        1157382\n",
       "PRODUCT_TYPE_ID          0\n",
       "PRODUCT_LENGTH           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 million data is a lot for my pc to handle\n",
    "#reducing to 100,000\n",
    "\n",
    "#first check for na values\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCT_ID         0\n",
       "TITLE              0\n",
       "BULLET_POINTS      0\n",
       "DESCRIPTION        0\n",
       "PRODUCT_TYPE_ID    0\n",
       "PRODUCT_LENGTH     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping all of them\n",
    "train_data = train_data.dropna()\n",
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1038458 entries, 2 to 2249697\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   PRODUCT_ID       1038458 non-null  int64  \n",
      " 1   TITLE            1038458 non-null  object \n",
      " 2   BULLET_POINTS    1038458 non-null  object \n",
      " 3   DESCRIPTION      1038458 non-null  object \n",
      " 4   PRODUCT_TYPE_ID  1038458 non-null  int64  \n",
      " 5   PRODUCT_LENGTH   1038458 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 55.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1million is still very big\n",
    "train_data=train_data.iloc[:100000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100000 entries, 2 to 216991\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   PRODUCT_ID       100000 non-null  int64  \n",
      " 1   TITLE            100000 non-null  object \n",
      " 2   BULLET_POINTS    100000 non-null  object \n",
      " 3   DESCRIPTION      100000 non-null  object \n",
      " 4   PRODUCT_TYPE_ID  100000 non-null  int64  \n",
      " 5   PRODUCT_LENGTH   100000 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "#400,000 values is feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aadit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aadit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aadit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#lets tokenize and convert to vectors!\n",
    "#creating a fxn is betterr\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#we will remove stopwords and also lemmatize them (convert to root form)\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def tokenize(x):\n",
    "    #lower case\n",
    "    x = str(x).lower()\n",
    "    #punctuation \n",
    "    x = x.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    #tokenize\n",
    "    tokens = word_tokenize(x)\n",
    "\n",
    "    #stop words\n",
    "    st = set(stopwords.words('english'))\n",
    "    tk = [t for t in tokens if not t in st]\n",
    "\n",
    "    #lemmatize\n",
    "    le = WordNetLemmatizer()\n",
    "    le_tk = [le.lemmatize(token) for token in tk]\n",
    "\n",
    "    return ' '.join(le_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try \n",
    "train_data[\"text\"] = train_data['TITLE'].apply(tokenize) + ' ' + train_data['DESCRIPTION'].apply(tokenize) + ' ' + train_data['BULLET_POINTS'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         priknik horn red electric air horn compressor ...\n",
       "3         alishah woman cotton ankle length legging comb...\n",
       "5         hin metal bucket shape plant pot indoor outdoo...\n",
       "7         delavala self adhesive kitchen backsplash wall...\n",
       "9         hexwell essential oil home fragrance oil aroma...\n",
       "                                ...                        \n",
       "216983    skechers woman max cushioning elite sneaker wh...\n",
       "216985    camel safety match box stick 1 packet 10 piece...\n",
       "216987    keyboard cover dell km636 wirelessdell kb216 w...\n",
       "216989    fast charger oppo a1k a1 k 1 k charger adapter...\n",
       "216991    coversgap samsung galaxy m31s back cover pink ...\n",
       "Name: text, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see\n",
    "train_data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "      <td>priknik horn red electric air horn compressor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "      <td>alishah woman cotton ankle length legging comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2152929</td>\n",
       "      <td>5725</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>hin metal bucket shape plant pot indoor outdoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026580</td>\n",
       "      <td>6030</td>\n",
       "      <td>984.251967</td>\n",
       "      <td>delavala self adhesive kitchen backsplash wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2998633</td>\n",
       "      <td>8201</td>\n",
       "      <td>393.700787</td>\n",
       "      <td>hexwell essential oil home fragrance oil aroma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  PRODUCT_TYPE_ID  PRODUCT_LENGTH   \n",
       "2     2765088             7537      748.031495  \\\n",
       "3     1594019             2996      787.401574   \n",
       "5     2152929             5725      950.000000   \n",
       "7     2026580             6030      984.251967   \n",
       "9     2998633             8201      393.700787   \n",
       "\n",
       "                                                text  \n",
       "2  priknik horn red electric air horn compressor ...  \n",
       "3  alishah woman cotton ankle length legging comb...  \n",
       "5  hin metal bucket shape plant pot indoor outdoo...  \n",
       "7  delavala self adhesive kitchen backsplash wall...  \n",
       "9  hexwell essential oil home fragrance oil aroma...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we drop the remaining columns\n",
    "train_data = train_data.drop(columns=[\"TITLE\",\"DESCRIPTION\",\"BULLET_POINTS\"])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving\n",
    "train_data.to_csv(\"FINAL_CLEANED.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perfecto!\n",
    "#now we convert our tokenized text into vectors using our tfidf vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "#if we dont set this max features, there will be a ton of features due to the big data size\n",
    "X = tfidf.fit_transform(train_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target\n",
    "y = train_data[\"PRODUCT_LENGTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use tensorflow for the particular problem\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(), #cos normalisation is just better\n",
    "    tf.keras.layers.Dense(500,activation='relu',input_shape=[250]),\n",
    "    tf.keras.layers.Dense(500,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(500,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1), #output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=\"mean_absolute_percentage_error\",\n",
    "              metrics=tf.keras.metrics.mean_absolute_percentage_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to make X_train and X_test into an array\n",
    "model.fit(X_train.toarray(),\n",
    "          y_train,\n",
    "          epochs=50,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test.toarray(),y_test,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 4ms/step\n",
      "Mean Absolute Percentage Error is : 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import sklearn.metrics as metrics\n",
    "y_pred = model.predict(X_test.toarray())\n",
    "# score = mean_absolute_percentage_error(y_test,y_pred)\n",
    "score = max( 0 , 100*(1-metrics.mean_absolute_percentage_error(y_test,y_pred)))\n",
    "print(f\"Mean Absolute Percentage Error is : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604373</td>\n",
       "      <td>Manuel d'Héliogravure Et de Photogravure En Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729783</td>\n",
       "      <td>DCGARING Microfiber Throw Blanket Warm Fuzzy P...</td>\n",
       "      <td>[QUALITY GUARANTEED: Luxury cozy plush polyest...</td>\n",
       "      <td>&lt;b&gt;DCGARING Throw Blanket&lt;/b&gt;&lt;br&gt;&lt;br&gt; &lt;b&gt;Size ...</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871949</td>\n",
       "      <td>I-Match Auto Parts Front License Plate Bracket...</td>\n",
       "      <td>[Front License Plate Bracket Made Of Plastic,D...</td>\n",
       "      <td>Replacement for The Following Vehicles:2020 LE...</td>\n",
       "      <td>7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1107571</td>\n",
       "      <td>PinMart Gold Plated Excellence in Service 1 Ye...</td>\n",
       "      <td>[Available as a single item or bulk packed. Se...</td>\n",
       "      <td>Our Excellence in Service Lapel Pins feature a...</td>\n",
       "      <td>12442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624253</td>\n",
       "      <td>Visual Mathematics, Illustrated by the TI-92 a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE   \n",
       "0      604373  Manuel d'Héliogravure Et de Photogravure En Re...  \\\n",
       "1     1729783  DCGARING Microfiber Throw Blanket Warm Fuzzy P...   \n",
       "2     1871949  I-Match Auto Parts Front License Plate Bracket...   \n",
       "3     1107571  PinMart Gold Plated Excellence in Service 1 Ye...   \n",
       "4      624253  Visual Mathematics, Illustrated by the TI-92 a...   \n",
       "\n",
       "                                       BULLET_POINTS   \n",
       "0                                                NaN  \\\n",
       "1  [QUALITY GUARANTEED: Luxury cozy plush polyest...   \n",
       "2  [Front License Plate Bracket Made Of Plastic,D...   \n",
       "3  [Available as a single item or bulk packed. Se...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID  \n",
       "0                                                NaN             6142  \n",
       "1  <b>DCGARING Throw Blanket</b><br><br> <b>Size ...             1622  \n",
       "2  Replacement for The Following Vehicles:2020 LE...             7540  \n",
       "3  Our Excellence in Service Lapel Pins feature a...            12442  \n",
       "4                                                NaN             6318  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 734736 entries, 0 to 734735\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   PRODUCT_ID       734736 non-null  int64 \n",
      " 1   TITLE            734731 non-null  object\n",
      " 2   BULLET_POINTS    458810 non-null  object\n",
      " 3   DESCRIPTION      354735 non-null  object\n",
      " 4   PRODUCT_TYPE_ID  734736 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 28.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying our token fxn \n",
    "\n",
    "test_data[\"text\"] = test_data[\"TITLE\"].apply(tokenize) + ' ' + test_data[\"BULLET_POINTS\"].apply(tokenize) + ' ' +test_data[\"DESCRIPTION\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604373</td>\n",
       "      <td>Manuel d'Héliogravure Et de Photogravure En Re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6142</td>\n",
       "      <td>manuel dhéliogravure et de photogravure en rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729783</td>\n",
       "      <td>DCGARING Microfiber Throw Blanket Warm Fuzzy P...</td>\n",
       "      <td>[QUALITY GUARANTEED: Luxury cozy plush polyest...</td>\n",
       "      <td>&lt;b&gt;DCGARING Throw Blanket&lt;/b&gt;&lt;br&gt;&lt;br&gt; &lt;b&gt;Size ...</td>\n",
       "      <td>1622</td>\n",
       "      <td>dcgaring microfiber throw blanket warm fuzzy p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871949</td>\n",
       "      <td>I-Match Auto Parts Front License Plate Bracket...</td>\n",
       "      <td>[Front License Plate Bracket Made Of Plastic,D...</td>\n",
       "      <td>Replacement for The Following Vehicles:2020 LE...</td>\n",
       "      <td>7540</td>\n",
       "      <td>imatch auto part front license plate bracket t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1107571</td>\n",
       "      <td>PinMart Gold Plated Excellence in Service 1 Ye...</td>\n",
       "      <td>[Available as a single item or bulk packed. Se...</td>\n",
       "      <td>Our Excellence in Service Lapel Pins feature a...</td>\n",
       "      <td>12442</td>\n",
       "      <td>pinmart gold plated excellence service 1 year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624253</td>\n",
       "      <td>Visual Mathematics, Illustrated by the TI-92 a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6318</td>\n",
       "      <td>visual mathematics illustrated ti92 ti89 nan nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE   \n",
       "0      604373  Manuel d'Héliogravure Et de Photogravure En Re...  \\\n",
       "1     1729783  DCGARING Microfiber Throw Blanket Warm Fuzzy P...   \n",
       "2     1871949  I-Match Auto Parts Front License Plate Bracket...   \n",
       "3     1107571  PinMart Gold Plated Excellence in Service 1 Ye...   \n",
       "4      624253  Visual Mathematics, Illustrated by the TI-92 a...   \n",
       "\n",
       "                                       BULLET_POINTS   \n",
       "0                                                NaN  \\\n",
       "1  [QUALITY GUARANTEED: Luxury cozy plush polyest...   \n",
       "2  [Front License Plate Bracket Made Of Plastic,D...   \n",
       "3  [Available as a single item or bulk packed. Se...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID   \n",
       "0                                                NaN             6142  \\\n",
       "1  <b>DCGARING Throw Blanket</b><br><br> <b>Size ...             1622   \n",
       "2  Replacement for The Following Vehicles:2020 LE...             7540   \n",
       "3  Our Excellence in Service Lapel Pins feature a...            12442   \n",
       "4                                                NaN             6318   \n",
       "\n",
       "                                                text  \n",
       "0  manuel dhéliogravure et de photogravure en rel...  \n",
       "1  dcgaring microfiber throw blanket warm fuzzy p...  \n",
       "2  imatch auto part front license plate bracket t...  \n",
       "3  pinmart gold plated excellence service 1 year ...  \n",
       "4   visual mathematics illustrated ti92 ti89 nan nan  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604373</td>\n",
       "      <td>6142</td>\n",
       "      <td>manuel dhéliogravure et de photogravure en rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729783</td>\n",
       "      <td>1622</td>\n",
       "      <td>dcgaring microfiber throw blanket warm fuzzy p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871949</td>\n",
       "      <td>7540</td>\n",
       "      <td>imatch auto part front license plate bracket t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1107571</td>\n",
       "      <td>12442</td>\n",
       "      <td>pinmart gold plated excellence service 1 year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624253</td>\n",
       "      <td>6318</td>\n",
       "      <td>visual mathematics illustrated ti92 ti89 nan nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID  PRODUCT_TYPE_ID   \n",
       "0      604373             6142  \\\n",
       "1     1729783             1622   \n",
       "2     1871949             7540   \n",
       "3     1107571            12442   \n",
       "4      624253             6318   \n",
       "\n",
       "                                                text  \n",
       "0  manuel dhéliogravure et de photogravure en rel...  \n",
       "1  dcgaring microfiber throw blanket warm fuzzy p...  \n",
       "2  imatch auto part front license plate bracket t...  \n",
       "3  pinmart gold plated excellence service 1 year ...  \n",
       "4   visual mathematics illustrated ti92 ti89 nan nan  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.drop(columns=[\"TITLE\",\"DESCRIPTION\",\"BULLET_POINTS\"])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"FINAL_CLEANED_TEST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>604373</td>\n",
       "      <td>701.093794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1729783</td>\n",
       "      <td>734.506163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871949</td>\n",
       "      <td>741.360258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1107571</td>\n",
       "      <td>730.327767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624253</td>\n",
       "      <td>666.847946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734731</th>\n",
       "      <td>921419</td>\n",
       "      <td>733.838809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734732</th>\n",
       "      <td>2456362</td>\n",
       "      <td>746.810825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734733</th>\n",
       "      <td>841529</td>\n",
       "      <td>691.127128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734734</th>\n",
       "      <td>1190194</td>\n",
       "      <td>757.643591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734735</th>\n",
       "      <td>1040810</td>\n",
       "      <td>754.110288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734736 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PRODUCT_ID  PRODUCT_LENGTH\n",
       "0           604373      701.093794\n",
       "1          1729783      734.506163\n",
       "2          1871949      741.360258\n",
       "3          1107571      730.327767\n",
       "4           624253      666.847946\n",
       "...            ...             ...\n",
       "734731      921419      733.838809\n",
       "734732     2456362      746.810825\n",
       "734733      841529      691.127128\n",
       "734734     1190194      757.643591\n",
       "734735     1040810      754.110288\n",
       "\n",
       "[734736 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_for_test_data = TfidfVectorizer(max_features=250)\n",
    "x_test_data = tf_for_test_data.fit_transform(test_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model = load_model(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "y_test_data_pred = model.predict(x_test_data.toarray())\n",
    "# final_score = max( 0 , 100*(1-metrics.mean_absolute_percentage_error(y_test_data,y_test_data_pred)))\n",
    "# final_score = mean_absolute_percentage_error(y_test_data,y_test_data_pred)\n",
    "# print(f\"MEAN ABSOLUTE PERCENTAGE ERROR: {final_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_data[\"PRODUCT_ID\"])\n",
    "\n",
    "# Add a new column with the y_pred values\n",
    "df[\"y_pred\"] = y_test_data_pred\n",
    "\n",
    "# Set the column names\n",
    "df.columns = [\"PRODUCT_ID\", \"PRODUCT_LENGTH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
